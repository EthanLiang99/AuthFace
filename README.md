<div align="center">

# AuthFace: Towards Authentic Blind Face Restoration with <br> Face-oriented Generative Diffusion Prior

<p>
  <img src="https://img.shields.io/badge/ACM%20MM-2025%20Oral-blueviolet?style=flat-square" />
  <img src="https://img.shields.io/badge/Task-Blind%20Face%20Restoration-ff69b4?style=flat-square" />
  <img src="https://img.shields.io/badge/License-Non--commercial-lightgrey?style=flat-square" />
  <a href="https://huggingface.co/Ethanliang99/AuthFace/tree/main">
    <img src="https://img.shields.io/badge/Hugging%20Face-Model-yellow?style=flat-square&logo=huggingface" />
  </a>
</p>

<div>
  <a href='https://scholar.google.com/citations?user=GHz1gUIAAAAJ&hl=zh-CN' target='_blank'>Guoqiang Liang</a><sup>1,2</sup>&emsp;
  <a href='https://scholar.google.com/citations?user=2cY2zwUAAAAJ&hl=zh-CN' target='_blank'>Qingnan Fan</a><sup>2</sup>&emsp;
  Bingtao Fu<sup>2</sup>&emsp;
  Jinwei Chen<sup>2</sup>&emsp;
  Hong Gu<sup>2</sup>&emsp;
  <a href='https://scholar.google.com/citations?user=SReb2csAAAAJ&hl=zh-CN' target='_blank'>Lin Wang</a><sup>1,3</sup>
</div>

<div>
  <sup>1</sup>Hong Kong University of Science and Technology (Guangzhou)<br>
  <sup>2</sup>Vivo, Hangzhou<br>
  <sup>3</sup>Hong Kong University of Science and Technology
</div>

</div>

<div align="center">
  <a href="#news-loudspeaker">News</a> •
  <a href="#authface-hq-dataset">Dataset</a> •
  <a href="#rocket-running-and-setup">Running</a> •
  <a href="#mortar_board-citation">Citation</a>
</div>

<p align="center">
  <img src="fig/teaser-2.png" width="90%" style="max-width: 100%; height: auto;" />
</p>

---

## News :loudspeaker:
- **[2026.01]** :fire: Our infernece code and models are rleased.
- **[2025.10]** :fire: **High-Quality Face Dataset Released!** We release **2,104** high-quality face images with detailed captions.
- **[2025.07]** Our paper has been accepted by **ACM MM 2025**.
- **[2024.10]** This repo is created.

---

## :file_folder: AuthFace-HQ Dataset

We present a high-quality face dataset for authentic blind face restoration. Due to proprietary constraints, the released dataset is limited to samples collected from Unsplash and is made available under a non-commercial license. The dataset consists of **2,104** high-resolution images, divided into male and female categories.

### 1. Download Dataset :inbox_tray:

| Dataset Content | Download Link | File Size |
| :--- | :---: | :---: |
| **AuthFace-HQ (Full)** | [**Google Drive**](https://drive.google.com/file/d/16z0TX_Nomq2lDUimBXd5I_YLkeZwLhvL/view?usp=sharing) | - |

### 2. Dataset Statistics
| Category | Count | Content | Description Format |
| :--- | :---: | :--- | :--- |
| **Woman** | 1,198 | High-Quality Face Images + Qwen Captions | `.png` image + `.json` metadata |
| **Man** | 906 | High-Quality Face Images + Qwen Captions | `.png` image + `.json` metadata |
| **Total** | **2,104** | - | - |

### 3. Directory Structure
The dataset is organized as follows. For each subset, we also provide `.json` files (generated by **Qwen**) containing detailed textual descriptions or attributes corresponding to the images.

<p align="center">
  <img src="fig/app-dataset2.png" width="90%" style="max-width: 100%; height: auto;" />
</p>
<p align="center"><sub>AuthFace-HQ dataset examples.</sub></p>

<details>
<summary>Click to view Dataset Directory Structure</summary>

```text
Dataset_Root
├── woman (1198 images + json captions)
│   ├── woman_11010_qwen.json <-- Textual description
│   ├── woman_11010.png       <-- Image file
│   ├── woman_10566.png
│   └── ...
│
├── man (906 images + json captions)
│   ├── man_14935_qwen.json  <-- Textual description
│   ├── man_14935.png        <-- Image file
│   ├── man_11609.png
│   └── ...
```
</details>

---

## :rocket: Running and Setup

In the project root, follow these steps:

### 1. Create and activate the environment
```bash
conda create -n authface python==3.10
conda activate authface
```

### 2. Install dependencies and download the model
```bash
pip install -r requriment.txt
huggingface-cli download Ethanliang99/AuthFace --local-dir /path/to/save --repo-type model
```

### 3. Run the test script
```bash
sh ./option/test/test_base.sh
```

<details>
<summary>Notes for <code>./option/test/test_base.sh</code></summary>

- Update the path-related arguments (e.g., `--pretrained_model_name_or_path`, `--validate_image_path`, `--output_dir`) to your local paths.
- `--prompt` and `--minor_color_fix_strength` can be customized, but the paper uses the default values in the script.
</details>

---

## :sparkles: Visual Results

<p align="center">
  <img src="fig/real-world_result.png" width="90%" style="max-width: 100%; height: auto;" />
</p>
<p align="center">
  <img src="fig/more_visual_results2.png" width="90%" style="max-width: 100%; height: auto;" />
</p>


## :mortar_board: Citation
If you find our dataset or code useful, please cite our paper:

```bibtex
@inproceedings{liang2025authface,
  title={AuthFace: Towards Authentic Blind Face Restoration with Face-oriented Generative Diffusion Prior},
  author={Liang, Guoqiang and Fan, Qingnan and Fu, Bingtao and Chen, Jinwei and Gu, Hong and Wang, Lin},
  booktitle={Proceedings of the 33rd ACM International Conference on Multimedia},
  year={2025}
}
```
